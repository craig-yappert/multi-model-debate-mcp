import * as vscode from 'vscode';
import { MCPClient } from '../mcp/client';
import { ConversationStore, ConversationEntry } from '../storage/conversation-store';
import { ContextAnalyzer, VSCodeContext } from './context-analyzer';
import { CommandLineManager } from './command-line-manager';
import { MattermostFallback } from './mattermost-fallback';

export class ChatParticipantManager {
    private mattermostFallback: MattermostFallback;

    constructor(
        private mcpClient: MCPClient,
        private conversationStore: ConversationStore,
        private contextAnalyzer: ContextAnalyzer,
        private commandLineManager: CommandLineManager
    ) {
        // Initialize Mattermost fallback with current configuration
        const config = vscode.workspace.getConfiguration('multiModelDebate');
        this.mattermostFallback = new MattermostFallback(config);
    }

    async handleChatRequest(
        persona: string,
        request: vscode.ChatRequest,
        context: vscode.ChatContext,
        stream: vscode.ChatResponseStream,
        token: vscode.CancellationToken
    ): Promise<{ metadata: { command: string } }> {

        const startTime = Date.now();

        try {
            // Show thinking indicator
            stream.progress(`${this.getPersonaDisplayName(persona)} is analyzing your request...`);

            // Gather rich context from VS Code
            const codeContext = await this.contextAnalyzer.gatherContext();

            // Get conversation history for context
            const conversationHistory = await this.conversationStore.getRecentConversations(5);

            // Prepare the request with all context
            const enhancedRequest = {
                message: request.prompt,
                persona: persona,
                vscode_context: codeContext,
                conversation_history: conversationHistory,
                workspace: vscode.workspace.name,
                timestamp: new Date().toISOString()
            };

            stream.progress(`Connecting to AI personas...`);

            // Get AI response from MCP server
            const aiResponse = await this.mcpClient.contribute(enhancedRequest);

            if (!aiResponse || aiResponse.trim().length === 0) {
                throw new Error('No response received from AI persona');
            }

            // Check if response contains command line suggestions
            const commandSuggestions = this.extractCommandSuggestions(aiResponse);

            // Stream the response
            stream.progress(`${this.getPersonaDisplayName(persona)} is responding...`);

            // Add persona header with icon
            stream.markdown(`**${this.getPersonaDisplayName(persona)}** ${this.getPersonaIcon(persona)}\n\n`);

            // Stream the main response
            await this.streamResponse(stream, aiResponse);

            // Handle command suggestions if present
            if (commandSuggestions.length > 0) {
                await this.handleCommandSuggestions(stream, commandSuggestions);
            }

            // Save conversation to workspace storage
            await this.conversationStore.saveConversation({
                id: '', // Will be generated by saveConversation
                persona,
                message: request.prompt,
                response: aiResponse,
                context: codeContext,
                timestamp: new Date().toISOString(),
                responseTime: Date.now() - startTime
            });

            // Add metadata about file context for VS Code
            const metadata = {
                command: `ai-response-${persona}`,
                fileContext: codeContext.activeFile?.path || 'none',
                hasErrors: codeContext.diagnostics.length > 0,
                isDebugging: codeContext.debugging?.isActive || false
            };

            return { metadata };

        } catch (error) {
            console.error(`Error in ${persona} chat participant:`, error);

            // Fallback to Mattermost or error response
            const fallbackResponse = await this.handleFallbackResponse(persona, request.prompt, error);
            stream.markdown(`**${this.getPersonaDisplayName(persona)}** ‚ö†Ô∏è\n\n${fallbackResponse}`);

            // Show fallback action buttons
            await this.mattermostFallback.handleFallbackActions(stream);

            // Prompt fallback configuration if needed
            await this.mattermostFallback.promptFallbackConfiguration();

            return { metadata: { command: `ai-error-${persona}` } };
        }
    }

    private async streamResponse(stream: vscode.ChatResponseStream, response: string): Promise<void> {
        // Stream response in chunks to make it feel more interactive
        const chunks = this.chunkResponse(response, 100);

        for (const chunk of chunks) {
            stream.markdown(chunk);
            // Small delay to make streaming visible
            await new Promise(resolve => setTimeout(resolve, 50));
        }
    }

    private chunkResponse(text: string, chunkSize: number): string[] {
        const chunks: string[] = [];
        let currentChunk = '';
        const words = text.split(' ');

        for (const word of words) {
            if ((currentChunk + ' ' + word).length > chunkSize && currentChunk.length > 0) {
                chunks.push(currentChunk);
                currentChunk = word;
            } else {
                currentChunk = currentChunk ? `${currentChunk} ${word}` : word;
            }
        }

        if (currentChunk) {
            chunks.push(currentChunk);
        }

        return chunks;
    }

    private extractCommandSuggestions(response: string): string[] {
        // Look for command suggestions in the response
        const commandPatterns = [
            /```(?:bash|shell|cmd)\n([\s\S]*?)\n```/g,
            /`([^`]+)`/g
        ];

        const suggestions: string[] = [];

        for (const pattern of commandPatterns) {
            let match;
            while ((match = pattern.exec(response)) !== null) {
                const command = match[1].trim();
                if (this.looksLikeCommand(command)) {
                    suggestions.push(command);
                }
            }
        }

        return [...new Set(suggestions)]; // Remove duplicates
    }

    private looksLikeCommand(text: string): boolean {
        // Simple heuristics to identify commands
        const commandIndicators = [
            'npm ', 'yarn ', 'git ', 'python ', 'node ',
            'cd ', 'ls ', 'mkdir ', 'rm ', 'cp ', 'mv ',
            'pip ', 'cargo ', 'go ', 'docker ', 'kubectl '
        ];

        return commandIndicators.some(indicator => text.toLowerCase().startsWith(indicator));
    }

    private async handleCommandSuggestions(stream: vscode.ChatResponseStream, suggestions: string[]): Promise<void> {
        if (!this.commandLineManager.isEnabled()) {
            return;
        }

        stream.markdown('\n\n---\n\n**Command Suggestions:**\n\n');

        for (const suggestion of suggestions) {
            // Create a button for each command suggestion
            stream.button({
                command: 'multiModelDebate.executeCommand',
                title: `‚ñ∂Ô∏è Run: ${suggestion}`,
                arguments: [suggestion]
            });
        }
    }

    private async handleFallbackResponse(persona: string, message: string, error: any): Promise<string> {
        // Use the dedicated Mattermost fallback handler
        return this.mattermostFallback.getFallbackResponse(persona, error);
    }

    private getPersonaDisplayName(persona: string): string {
        switch (persona) {
            case 'claude-research':
                return 'Claude Research';
            case 'kiro':
                return 'Kiro';
            default:
                return persona;
        }
    }

    private getPersonaIcon(persona: string): string {
        switch (persona) {
            case 'claude-research':
                return 'üß†'; // Brain for analytical thinking
            case 'kiro':
                return 'üîß'; // Tools for practical execution
            default:
                return 'ü§ñ';
        }
    }
}